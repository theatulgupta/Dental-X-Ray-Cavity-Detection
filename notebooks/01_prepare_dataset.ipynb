{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "839fcd99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.13.5 | packaged by Anaconda, Inc. | (main, Jun 12 2025, 11:23:37) [Clang 14.0.6 ]\n",
      "Executable: /Users/theatulgupta/Desktop/Deep Learning Project/dental-xray-cavity-detection/.venv/bin/python\n",
      "Platform: macOS-26.0.1-arm64-arm-64bit-Mach-O\n",
      "ultralytics, torch, numpy OK\n",
      "Torch: 2.9.0\n"
     ]
    }
   ],
   "source": [
    "# Diagnostics: run this after selecting the kernel \"Python (dental-xray)\"\n",
    "import sys, platform\n",
    "print(\"Python:\", sys.version)\n",
    "print(\"Executable:\", sys.executable)\n",
    "print(\"Platform:\", platform.platform())\n",
    "try:\n",
    "    from ultralytics import YOLO\n",
    "    import torch, numpy as np\n",
    "    print(\"ultralytics, torch, numpy OK\")\n",
    "    print(\"Torch:\", torch.__version__)\n",
    "except Exception as e:\n",
    "    print(\"Import error:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "381a1eaf",
   "metadata": {},
   "source": [
    "# Dataset Preparation for Dental X-ray Cavity Detection\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook prepares the dataset for training YOLO models. It handles:\n",
    "\n",
    "1. **Data Collection**: Gathers all X-ray images from raw data folder\n",
    "2. **Dataset Splitting**: Divides images into 70% train, 15% validation, 15% test\n",
    "3. **YOLO Format**: Ensures labels are in YOLO format (normalized bounding boxes)\n",
    "4. **Configuration**: Creates `dataset.yaml` file for YOLO training\n",
    "\n",
    "## Dataset Structure\n",
    "\n",
    "After running this notebook, you'll have:\n",
    "\n",
    "```\n",
    "data/processed/\n",
    "├── train/\n",
    "│   ├── images/     # Training X-ray images (70%)\n",
    "│   └── labels/     # Training YOLO labels (.txt)\n",
    "├── val/\n",
    "│   ├── images/     # Validation X-ray images (15%)\n",
    "│   └── labels/     # Validation YOLO labels (.txt)\n",
    "├── test/\n",
    "│   ├── images/     # Test X-ray images (15%)\n",
    "│   └── labels/     # Test YOLO labels (.txt)\n",
    "└── dataset.yaml    # YOLO configuration file\n",
    "```\n",
    "\n",
    "## Cavity Classes\n",
    "\n",
    "Our dataset has **4 cavity severity levels**:\n",
    "\n",
    "- **Class 0**: cavity_class_0 (minimal)\n",
    "- **Class 1**: cavity_class_1 (mild)\n",
    "- **Class 2**: cavity_class_2 (moderate)\n",
    "- **Class 3**: cavity_class_3 (severe)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f069553",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required dependencies (uncomment if running for the first time)\n",
    "# !pip install -q ultralytics==8.2.0 opencv-python pillow matplotlib numpy torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f230750e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: /Users/theatulgupta/Desktop/Deep Learning Project/dental-xray-cavity-detection\n",
      "Raw data location: /Users/theatulgupta/Desktop/Deep Learning Project/dental-xray-cavity-detection/data/raw/dental\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# IMPORT LIBRARIES AND SETUP PATHS\n",
    "# ============================================================\n",
    "\n",
    "# Import necessary libraries\n",
    "from ultralytics import YOLO  # For YOLO object detection model\n",
    "import os, shutil, glob, random, json, math  # Standard Python libraries\n",
    "from pathlib import Path  # For handling file paths in a cross-platform way\n",
    "from PIL import Image  # For image processing\n",
    "\n",
    "# Detect project root correctly when running from notebooks/ folder\n",
    "# This ensures paths work whether you run from notebooks/ or project root\n",
    "project_root = (Path('..').resolve() if Path.cwd().name == 'notebooks' else Path('.').resolve())\n",
    "\n",
    "# Define all important paths for our project\n",
    "data_raw = project_root / 'data' / 'raw' / 'dental'  # Where raw X-ray images are stored\n",
    "images_glob = ['*.jpg','*.jpeg','*.png','*.bmp']  # Image file extensions to look for\n",
    "processed = project_root / 'data' / 'processed'  # Where processed dataset will be saved\n",
    "\n",
    "# Create separate folders for training, validation, and test data\n",
    "train_images = processed / 'train' / 'images'  # Training images folder\n",
    "train_labels = processed / 'train' / 'labels'  # Training labels folder\n",
    "val_images = processed / 'val' / 'images'  # Validation images folder\n",
    "val_labels = processed / 'val' / 'labels'  # Validation labels folder\n",
    "test_images = processed / 'test' / 'images'  # Test images folder\n",
    "test_labels = processed / 'test' / 'labels'  # Test labels folder\n",
    "\n",
    "# Create folder for saving trained models\n",
    "models_dir = project_root / 'models'\n",
    "models_dir.mkdir(parents=True, exist_ok=True)  # Create if doesn't exist\n",
    "\n",
    "# Create all required directories\n",
    "for d in [train_images, train_labels, val_images, val_labels, test_images, test_labels]:\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Print paths to verify everything is set up correctly\n",
    "print('Project root:', project_root)\n",
    "print('Raw data location:', data_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af9e02c",
   "metadata": {},
   "source": [
    "## Step 1: Split Dataset into Train, Validation, and Test Sets\n",
    "\n",
    "This section:\n",
    "\n",
    "- Searches for all X-ray images in the raw data folder\n",
    "- Locates corresponding YOLO labels (if available)\n",
    "- Randomly splits images into 70% train, 15% validation, 15% test\n",
    "- Copies images and labels to appropriate folders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dac43915",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total images found: 128\n",
      "Label directory: /Users/theatulgupta/Desktop/Deep Learning Project/dental-xray-cavity-detection/data/raw/dental/object_detection_labels\n",
      "Training: 89 | Validation: 19 | Test: 20\n",
      "\n",
      "✅ Dataset preparation complete!\n",
      "Processed dataset location: /Users/theatulgupta/Desktop/Deep Learning Project/dental-xray-cavity-detection/data/processed\n",
      "Training: 58 images, 58 labels\n",
      "Validation: 17 images, 17 labels\n",
      "Test: 19 images, 19 labels\n",
      "\n",
      "✅ Dataset preparation complete!\n",
      "Processed dataset location: /Users/theatulgupta/Desktop/Deep Learning Project/dental-xray-cavity-detection/data/processed\n",
      "Training: 58 images, 58 labels\n",
      "Validation: 17 images, 17 labels\n",
      "Test: 19 images, 19 labels\n"
     ]
    }
   ],
   "source": [
    "# Step 1.1: Find all images in the raw data directory\n",
    "# We check both 'images' subfolder and root of 'dental' folder\n",
    "img_dir_candidates = [data_raw / 'images', data_raw]\n",
    "all_imgs = []  # List to store all found image paths\n",
    "\n",
    "# Loop through candidate directories and find all images\n",
    "for d in img_dir_candidates:\n",
    "    if d.exists():  # Check if directory exists\n",
    "        for pat in images_glob:  # Check each image extension\n",
    "            all_imgs += list(d.rglob(pat))  # Recursively find all matching files\n",
    "\n",
    "all_imgs = sorted(set(all_imgs))  # Remove duplicates and sort\n",
    "print('Total images found:', len(all_imgs))\n",
    "\n",
    "# Step 1.2: Locate YOLO label files (if they exist)\n",
    "# Labels are typically in 'labels' or 'object_detection_labels' folder\n",
    "possible_label_dirs = [data_raw / 'labels', data_raw / 'object_detection_labels']\n",
    "label_root = None  # Variable to store the label directory path\n",
    "\n",
    "for cand in possible_label_dirs:\n",
    "    if cand.exists():\n",
    "        label_root = cand\n",
    "        break  # Stop when we find the first valid label directory\n",
    "\n",
    "print('Label directory:', label_root)\n",
    "\n",
    "# Step 1.3: Perform train/val/test split (70/15/15)\n",
    "random.seed(42)  # Set random seed for reproducibility (same split every time)\n",
    "random.shuffle(all_imgs)  # Randomly shuffle the images\n",
    "\n",
    "# Calculate split points\n",
    "train_split = int(0.70 * len(all_imgs))  # 70% for training\n",
    "val_split = int(0.85 * len(all_imgs))    # Next 15% for validation (70% + 15% = 85%)\n",
    "\n",
    "# Split the data\n",
    "train_list = all_imgs[:train_split]           # First 70% for training\n",
    "val_list = all_imgs[train_split:val_split]    # Next 15% for validation\n",
    "test_list = all_imgs[val_split:]              # Remaining 15% for testing\n",
    "\n",
    "print(f'Training: {len(train_list)} | Validation: {len(val_list)} | Test: {len(test_list)}')\n",
    "\n",
    "# Step 1.4: Define helper function to copy images and their labels\n",
    "def move_with_label(img_paths, out_img_dir, out_lbl_dir):\n",
    "    \"\"\"\n",
    "    Copies images and their corresponding label files to output directories.\n",
    "    \n",
    "    Args:\n",
    "        img_paths: List of image file paths to copy\n",
    "        out_img_dir: Destination directory for images\n",
    "        out_lbl_dir: Destination directory for labels\n",
    "    \"\"\"\n",
    "    for ip in img_paths:\n",
    "        rel = ip.stem  # Get filename without extension (e.g., 'p1' from 'p1.png')\n",
    "        \n",
    "        # Copy the image file\n",
    "        dst_img = out_img_dir / ip.name\n",
    "        shutil.copy2(ip, dst_img)\n",
    "        \n",
    "        # Copy the corresponding label file if it exists\n",
    "        if label_root is not None:\n",
    "            cand = label_root / f'{rel}.txt'  # Look for .txt file with same name\n",
    "            if cand.exists():\n",
    "                shutil.copy2(cand, out_lbl_dir / cand.name)\n",
    "\n",
    "# Step 1.5: Clear any previous data from processed folders\n",
    "for d in [train_images, train_labels, val_images, val_labels, test_images, test_labels]:\n",
    "    for p in d.glob('*'):\n",
    "        if p.is_file(): \n",
    "            p.unlink()  # Delete the file\n",
    "\n",
    "# Step 1.6: Copy images and labels to train/val/test folders\n",
    "move_with_label(train_list, train_images, train_labels)\n",
    "move_with_label(val_list, val_images, val_labels)\n",
    "move_with_label(test_list, test_images, test_labels)\n",
    "\n",
    "# Step 1.7: Verify the dataset was created successfully\n",
    "print('\\n✅ Dataset preparation complete!')\n",
    "print('Processed dataset location:', processed)\n",
    "print(f'Training: {len(list(train_images.glob(\"*\")))} images, {len(list(train_labels.glob(\"*.txt\")))} labels')\n",
    "print(f'Validation: {len(list(val_images.glob(\"*\")))} images, {len(list(val_labels.glob(\"*.txt\")))} labels')\n",
    "print(f'Test: {len(list(test_images.glob(\"*\")))} images, {len(list(test_labels.glob(\"*.txt\")))} labels')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b55ac1b",
   "metadata": {},
   "source": [
    "## Step 2: Create dataset.yaml Configuration File\n",
    "\n",
    "YOLO requires a YAML configuration file that specifies:\n",
    "\n",
    "- Path to training images\n",
    "- Path to validation images\n",
    "- Path to test images\n",
    "- Number of classes (nc)\n",
    "- Class names\n",
    "\n",
    "Our dataset has **4 cavity severity classes**: 0, 1, 2, 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3565acbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ dataset.yaml created successfully!\n",
      "\n",
      "Configuration:\n",
      "train: /Users/theatulgupta/Desktop/Deep Learning Project/dental-xray-cavity-detection/data/processed/train/images\n",
      "val: /Users/theatulgupta/Desktop/Deep Learning Project/dental-xray-cavity-detection/data/processed/val/images\n",
      "test: /Users/theatulgupta/Desktop/Deep Learning Project/dental-xray-cavity-detection/data/processed/test/images\n",
      "nc: 4\n",
      "names: [cavity_class_0, cavity_class_1, cavity_class_2, cavity_class_3]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create the dataset.yaml configuration file\n",
    "dataset_yaml = processed / 'dataset.yaml'\n",
    "\n",
    "# Write the configuration\n",
    "# - train: absolute path to training images folder\n",
    "# - val: absolute path to validation images folder\n",
    "# - test: absolute path to test images folder\n",
    "# - nc: number of classes (4 for our cavity severity levels)\n",
    "# - names: list of class names corresponding to class IDs 0, 1, 2, 3\n",
    "dataset_yaml.write_text(\n",
    "    f\"train: {train_images.resolve()}\\n\"  # Absolute path to training images\n",
    "    f\"val: {val_images.resolve()}\\n\"  # Absolute path to validation images\n",
    "    f\"test: {test_images.resolve()}\\n\"  # Absolute path to test images\n",
    "    'nc: 4\\n'  # Number of classes (0, 1, 2, 3)\n",
    "    'names: [cavity_class_0, cavity_class_1, cavity_class_2, cavity_class_3]\\n'  # Class names\n",
    ")\n",
    "\n",
    "# Display the created configuration file\n",
    "print('✅ dataset.yaml created successfully!\\n')\n",
    "print('Configuration:')\n",
    "print(dataset_yaml.read_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d18618d3",
   "metadata": {},
   "source": [
    "## ✅ Dataset Preparation Complete!\n",
    "\n",
    "You can now proceed to train models:\n",
    "\n",
    "- **YOLOv8**: Open `02_train_yolov8.ipynb`\n",
    "- **YOLOv12**: Open `03_train_yolov12.ipynb`\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
