{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f91a64c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.13.5 | packaged by Anaconda, Inc. | (main, Jun 12 2025, 11:23:37) [Clang 14.0.6 ]\n",
      "PyTorch: 2.9.0\n",
      "Device: MPS\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import sys\n",
    "\n",
    "print(f\"Python: {sys.version}\")\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"Device: {'CUDA' if torch.cuda.is_available() else 'MPS' if torch.backends.mps.is_available() else 'CPU'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ff7dc94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "import time\n",
    "import glob\n",
    "import json\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from ultralytics import YOLO\n",
    "from thop import profile\n",
    "from pathlib import Path\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu'\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afdbd603",
   "metadata": {},
   "source": [
    "# YOLOv8 Training\n",
    "\n",
    "Train YOLOv8n model on the dental X-ray dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "810f40e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Data config: /Users/theatulgupta/Desktop/Deep Learning Project/dental-xray-cavity-detection/data/processed/dataset.yaml\n",
      "âœ“ Models dir: /Users/theatulgupta/Desktop/Deep Learning Project/dental-xray-cavity-detection/models\n"
     ]
    }
   ],
   "source": [
    "# Setup paths\n",
    "project_root = Path('..').resolve() if Path.cwd().name == 'notebooks' else Path('.').resolve()\n",
    "processed = project_root / 'data' / 'processed'\n",
    "models_dir = project_root / 'models'\n",
    "models_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Locate dataset\n",
    "data_yaml_path = processed / 'dataset.yaml'\n",
    "if not data_yaml_path.exists():\n",
    "    raise FileNotFoundError(\"Dataset not found! Run 01_prepare_dataset.ipynb first.\")\n",
    "\n",
    "data_yaml_path = str(data_yaml_path)\n",
    "test_images_path = Path(data_yaml_path).parent / \"test\" / \"images\"\n",
    "\n",
    "print(f\"âœ“ Data config: {data_yaml_path}\")\n",
    "print(f\"âœ“ Models dir: {models_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a9afb9",
   "metadata": {},
   "source": [
    "## Train Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d29b4530",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training YOLOv8n...\n",
      "Ultralytics 8.3.63 ðŸš€ Python-3.13.5 torch-2.9.0 MPS (Apple M1)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=/Users/theatulgupta/Desktop/Deep Learning Project/dental-xray-cavity-detection/data/processed/dataset.yaml, epochs=1, time=None, patience=100, batch=8, imgsz=640, save=True, save_period=-1, cache=False, device=mps, workers=8, project=None, name=yolov8n_dental4, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.0, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.1, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=/Users/theatulgupta/Desktop/Deep Learning Project/dental-xray-cavity-detection/yolov12/runs/detect/yolov8n_dental4\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=/Users/theatulgupta/Desktop/Deep Learning Project/dental-xray-cavity-detection/data/processed/dataset.yaml, epochs=1, time=None, patience=100, batch=8, imgsz=640, save=True, save_period=-1, cache=False, device=mps, workers=8, project=None, name=yolov8n_dental4, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.0, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.1, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=/Users/theatulgupta/Desktop/Deep Learning Project/dental-xray-cavity-detection/yolov12/runs/detect/yolov8n_dental4\n",
      "Overriding model.yaml nc=80 with nc=4\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "Overriding model.yaml nc=80 with nc=4\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    752092  ultralytics.nn.modules.head.Detect           [4, [64, 128, 256]]           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    752092  ultralytics.nn.modules.head.Detect           [4, [64, 128, 256]]           \n",
      "Model summary: 225 layers, 3,011,628 parameters, 3,011,612 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n",
      "Model summary: 225 layers, 3,011,628 parameters, 3,011,612 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/theatulgupta/Desktop/Deep Learning Project/dental-xray-cavity-detection/data/processed/train/labels.cache... 58 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 58/58 [00:00<?, ?it/s]\n",
      "/Users/theatulgupta/Desktop/Deep Learning Project/dental-xray-cavity-detection/.venv/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/theatulgupta/Desktop/Deep Learning Project/dental-xray-cavity-detection/data/processed/train/labels.cache... 58 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 58/58 [00:00<?, ?it/s]\n",
      "/Users/theatulgupta/Desktop/Deep Learning Project/dental-xray-cavity-detection/.venv/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/theatulgupta/Desktop/Deep Learning Project/dental-xray-cavity-detection/data/processed/val/labels.cache... 17 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.00125, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1m/Users/theatulgupta/Desktop/Deep Learning Project/dental-xray-cavity-detection/yolov12/runs/detect/yolov8n_dental4\u001b[0m\n",
      "Starting training for 1 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.00125, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1m/Users/theatulgupta/Desktop/Deep Learning Project/dental-xray-cavity-detection/yolov12/runs/detect/yolov8n_dental4\u001b[0m\n",
      "Starting training for 1 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "        1/1      3.58G      1.499      4.158      1.282        141        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:11<00:00,  1.43s/it]\n",
      "        1/1      3.58G      1.499      4.158      1.282        141        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:11<00:00,  1.43s/it]/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17        499          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1 epochs completed in 0.004 hours.\n",
      "Optimizer stripped from /Users/theatulgupta/Desktop/Deep Learning Project/dental-xray-cavity-detection/yolov12/runs/detect/yolov8n_dental4/weights/last.pt, 6.2MB\n",
      "Optimizer stripped from /Users/theatulgupta/Desktop/Deep Learning Project/dental-xray-cavity-detection/yolov12/runs/detect/yolov8n_dental4/weights/last.pt, 6.2MB\n",
      "Optimizer stripped from /Users/theatulgupta/Desktop/Deep Learning Project/dental-xray-cavity-detection/yolov12/runs/detect/yolov8n_dental4/weights/best.pt, 6.2MB\n",
      "\n",
      "Validating /Users/theatulgupta/Desktop/Deep Learning Project/dental-xray-cavity-detection/yolov12/runs/detect/yolov8n_dental4/weights/best.pt...\n",
      "Ultralytics 8.3.63 ðŸš€ Python-3.13.5 torch-2.9.0 MPS (Apple M1)\n",
      "Optimizer stripped from /Users/theatulgupta/Desktop/Deep Learning Project/dental-xray-cavity-detection/yolov12/runs/detect/yolov8n_dental4/weights/best.pt, 6.2MB\n",
      "\n",
      "Validating /Users/theatulgupta/Desktop/Deep Learning Project/dental-xray-cavity-detection/yolov12/runs/detect/yolov8n_dental4/weights/best.pt...\n",
      "Ultralytics 8.3.63 ðŸš€ Python-3.13.5 torch-2.9.0 MPS (Apple M1)\n",
      "Model summary (fused): 168 layers, 3,006,428 parameters, 0 gradients, 8.1 GFLOPs\n",
      "Model summary (fused): 168 layers, 3,006,428 parameters, 0 gradients, 8.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  2.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17        499          0          0          0          0\n",
      "Speed: 1.9ms preprocess, 14.5ms inference, 0.0ms loss, 5.4ms postprocess per image\n",
      "Speed: 1.9ms preprocess, 14.5ms inference, 0.0ms loss, 5.4ms postprocess per image\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ“ Training complete: 16.67s\n",
      "âœ“ Best weights: /Users/theatulgupta/Desktop/Deep Learning Project/dental-xray-cavity-detection/yolov12/runs/detect/yolov8n_dental4/weights/best.pt\n"
     ]
    }
   ],
   "source": [
    "model_v8 = YOLO('yolov8n.pt')\n",
    "\n",
    "print(\"Training YOLOv8n...\")\n",
    "start_time_v8 = time.time()\n",
    "results_v8 = model_v8.train(\n",
    "    data=data_yaml_path,\n",
    "    epochs=1,  # Change to 50 for production\n",
    "    imgsz=640,\n",
    "    batch=8,\n",
    "    name='yolov8n_dental',\n",
    "    device=device,\n",
    "    verbose=True,  # Shows progress bar with epochs\n",
    "    plots=False,   # Disable plot generation\n",
    "    save=True\n",
    ")\n",
    "train_time_v8 = time.time() - start_time_v8\n",
    "\n",
    "path_v8_best_weights = results_v8.save_dir / 'weights' / 'best.pt'\n",
    "print(f\"\\nâœ“ Training complete: {train_time_v8:.2f}s\")\n",
    "print(f\"âœ“ Best weights: {path_v8_best_weights}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb68c9f",
   "metadata": {},
   "source": [
    "## Profile Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "277fa57b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Profiling model...\n",
      "âœ“ Parameters: 3.01M | FLOPs: 4.10G\n",
      "âœ“ Parameters: 3.01M | FLOPs: 4.10G\n"
     ]
    }
   ],
   "source": [
    "print(\"Profiling model...\")\n",
    "model_v8_trained = YOLO(path_v8_best_weights)\n",
    "\n",
    "# Move to CPU for THOP compatibility\n",
    "model_cpu = model_v8_trained.model.cpu()\n",
    "dummy_input = torch.randn(1, 3, 640, 640)\n",
    "\n",
    "flops_v8, params_v8 = profile(model_cpu, inputs=(dummy_input,), verbose=False)\n",
    "print(f\"âœ“ Parameters: {params_v8/1e6:.2f}M | FLOPs: {flops_v8/1e9:.2f}G\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69928135",
   "metadata": {},
   "source": [
    "## Measure Inference Time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "918444bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Measuring inference time...\n",
      "âœ“ Avg inference: 65.57ms/image (19 test images)\n",
      "âœ“ Avg inference: 65.57ms/image (19 test images)\n"
     ]
    }
   ],
   "source": [
    "print(\"Measuring inference time...\")\n",
    "# Reload model on correct device for inference\n",
    "model_v8_trained = YOLO(path_v8_best_weights)\n",
    "\n",
    "test_images = list(test_images_path.glob('*.jpg')) + list(test_images_path.glob('*.png'))\n",
    "\n",
    "def get_avg_inference_time(model, image_list):\n",
    "    if len(image_list) == 0:\n",
    "        return 0\n",
    "    _ = model(image_list[0], verbose=False)  # Warm-up\n",
    "    total_time = 0\n",
    "    for img in image_list:\n",
    "        start = time.perf_counter()\n",
    "        _ = model(img, verbose=False)\n",
    "        total_time += time.perf_counter() - start\n",
    "    return (total_time / len(image_list)) * 1000\n",
    "\n",
    "avg_inf_time_v8 = get_avg_inference_time(model_v8_trained, test_images[:10])\n",
    "print(f\"âœ“ Avg inference: {avg_inf_time_v8:.2f}ms/image ({len(test_images)} test images)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4725b153",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on test set...\n",
      "Ultralytics 8.3.63 ðŸš€ Python-3.13.5 torch-2.9.0 CPU (Apple M1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/theatulgupta/Desktop/Deep Learning Project/dental-xray-cavity-detection/data/processed/test/labels.cache... 19 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<?, ?it/s]\n",
      "/Users/theatulgupta/Desktop/Deep Learning Project/dental-xray-cavity-detection/.venv/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/theatulgupta/Desktop/Deep Learning Project/dental-xray-cavity-detection/data/processed/test/labels.cache... 19 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<?, ?it/s]\n",
      "/Users/theatulgupta/Desktop/Deep Learning Project/dental-xray-cavity-detection/.venv/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:02<00:00,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         19        551          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speed: 1.2ms preprocess, 118.8ms inference, 0.0ms loss, 1.1ms postprocess per image\n",
      "Results saved to \u001b[1m/Users/theatulgupta/Desktop/Deep Learning Project/dental-xray-cavity-detection/yolov12/runs/detect/val\u001b[0m\n",
      "âœ“ mAP@50: 0.0000 | mAP@50-95: 0.0000\n",
      "Results saved to \u001b[1m/Users/theatulgupta/Desktop/Deep Learning Project/dental-xray-cavity-detection/yolov12/runs/detect/val\u001b[0m\n",
      "âœ“ mAP@50: 0.0000 | mAP@50-95: 0.0000\n"
     ]
    }
   ],
   "source": [
    "print(\"Evaluating on test set...\")\n",
    "metrics_v8 = model_v8_trained.val(split='test', data=data_yaml_path, verbose=False)\n",
    "map50_v8 = metrics_v8.box.map50\n",
    "map50_95_v8 = metrics_v8.box.map\n",
    "\n",
    "print(f\"âœ“ mAP@50: {map50_v8:.4f} | mAP@50-95: {map50_95_v8:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74043041",
   "metadata": {},
   "source": [
    "## Save Results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bd2e427c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model and metrics...\n",
      "\n",
      "============================================================\n",
      "âœ“ Model saved: /Users/theatulgupta/Desktop/Deep Learning Project/dental-xray-cavity-detection/models/yolov8_best.pt\n",
      "âœ“ Metrics saved: /Users/theatulgupta/Desktop/Deep Learning Project/dental-xray-cavity-detection/models/yolov8_metrics.json\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"Saving model and metrics...\")\n",
    "shutil.copy(path_v8_best_weights, models_dir / 'yolov8_best.pt')\n",
    "\n",
    "metrics_data = {\n",
    "    'model': 'YOLOv8n',\n",
    "    'training_time': train_time_v8,\n",
    "    'params': params_v8 / 1e6,\n",
    "    'inference_time_ms': avg_inf_time_v8,\n",
    "    'map50': float(map50_v8),\n",
    "    'map50_95': float(map50_95_v8)\n",
    "}\n",
    "\n",
    "with open(models_dir / 'yolov8_metrics.json', 'w') as f:\n",
    "    json.dump(metrics_data, f, indent=2)\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"âœ“ Model saved: {models_dir}/yolov8_best.pt\")\n",
    "print(f\"âœ“ Metrics saved: {models_dir}/yolov8_metrics.json\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b793d37",
   "metadata": {},
   "source": [
    "## Visualize Predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dedd8ef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualizing sample predictions...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… YOLOv8 training complete!\n"
     ]
    }
   ],
   "source": [
    "print(\"Visualizing sample predictions...\")\n",
    "sample_images = test_images[:3]\n",
    "fig, axes = plt.subplots(1, len(sample_images), figsize=(15, 5))\n",
    "if len(sample_images) == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "for idx, img_path in enumerate(sample_images):\n",
    "    results = model_v8_trained(img_path, verbose=False)\n",
    "    plotted = results[0].plot()[..., ::-1]  # BGR to RGB\n",
    "    axes[idx].imshow(plotted)\n",
    "    axes[idx].axis('off')\n",
    "    axes[idx].set_title(f\"Sample {idx+1}\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "print(\"\\nâœ… YOLOv8 training complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
