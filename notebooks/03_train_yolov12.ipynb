{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7fe78fad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.13.5 | packaged by Anaconda, Inc. | (main, Jun 12 2025, 11:23:37) [Clang 14.0.6 ]\n",
      "PyTorch: 2.9.0\n",
      "Device: MPS\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import sys\n",
    "\n",
    "print(f\"Python: {sys.version}\")\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"Device: {'CUDA' if torch.cuda.is_available() else 'MPS' if torch.backends.mps.is_available() else 'CPU'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aaf9c913",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/theatulgupta/Desktop/Deep Learning Project/dental-xray-cavity-detection/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FlashAttention is not available on this device. Using scaled_dot_product_attention instead.\n",
      "Using device: mps\n",
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import glob\n",
    "import json\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from ultralytics import YOLO\n",
    "from thop import profile\n",
    "from pathlib import Path\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu'\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025d3166",
   "metadata": {},
   "source": [
    "# YOLOv12 Training\n",
    "\n",
    "Train YOLOv12n model on the dental X-ray dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4d7497a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ YOLOv12 repo: /Users/theatulgupta/Desktop/Deep Learning Project/dental-xray-cavity-detection/yolov12\n"
     ]
    }
   ],
   "source": [
    "# Setup YOLOv12 path\n",
    "project_root = Path('..').resolve() if Path.cwd().name == 'notebooks' else Path('.').resolve()\n",
    "yolov12_repo_path = project_root / 'yolov12'\n",
    "sys.path.insert(0, str(yolov12_repo_path))\n",
    "\n",
    "print(f\"âœ“ YOLOv12 repo: {yolov12_repo_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9702ce23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Data config: /Users/theatulgupta/Desktop/Deep Learning Project/dental-xray-cavity-detection/data/processed/dataset.yaml\n",
      "âœ“ Models dir: /Users/theatulgupta/Desktop/Deep Learning Project/dental-xray-cavity-detection/models\n"
     ]
    }
   ],
   "source": [
    "# Setup paths\n",
    "processed = project_root / 'data' / 'processed'\n",
    "models_dir = project_root / 'models'\n",
    "models_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Locate dataset\n",
    "data_yaml_path = processed / 'dataset.yaml'\n",
    "if not data_yaml_path.exists():\n",
    "    raise FileNotFoundError(\"Dataset not found! Run 01_prepare_dataset.ipynb first.\")\n",
    "\n",
    "data_yaml_path = str(data_yaml_path)\n",
    "test_images_path = Path(data_yaml_path).parent / \"test\" / \"images\"\n",
    "\n",
    "print(f\"âœ“ Data config: {data_yaml_path}\")\n",
    "print(f\"âœ“ Models dir: {models_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b0e0d19",
   "metadata": {},
   "source": [
    "## Train Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a8ab772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš  YOLOv12 not compatible with MPS, using CPU instead\n",
      "Training YOLOv12n on cpu...\n",
      "New https://pypi.org/project/ultralytics/8.3.225 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "New https://pypi.org/project/ultralytics/8.3.225 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.63 ðŸš€ Python-3.13.5 torch-2.9.0 CPU (Apple M1)\n",
      "Ultralytics 8.3.63 ðŸš€ Python-3.13.5 torch-2.9.0 CPU (Apple M1)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov12n.pt, data=/Users/theatulgupta/Desktop/Deep Learning Project/dental-xray-cavity-detection/data/processed/dataset.yaml, epochs=1, time=None, patience=100, batch=8, imgsz=640, save=True, save_period=-1, cache=False, device=cpu, workers=8, project=None, name=yolov12n_dental2, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.0, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.1, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=/Users/theatulgupta/Desktop/Deep Learning Project/dental-xray-cavity-detection/yolov12/runs/detect/yolov12n_dental2\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov12n.pt, data=/Users/theatulgupta/Desktop/Deep Learning Project/dental-xray-cavity-detection/data/processed/dataset.yaml, epochs=1, time=None, patience=100, batch=8, imgsz=640, save=True, save_period=-1, cache=False, device=cpu, workers=8, project=None, name=yolov12n_dental2, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.0, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.1, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=/Users/theatulgupta/Desktop/Deep Learning Project/dental-xray-cavity-detection/yolov12/runs/detect/yolov12n_dental2\n",
      "Overriding model.yaml nc=80 with nc=4\n",
      "Overriding model.yaml nc=80 with nc=4\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      2368  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2, 1, 2]          \n",
      "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
      "  3                  -1  1      9344  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2, 1, 4]          \n",
      "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
      "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      2368  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2, 1, 2]          \n",
      "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
      "  3                  -1  1      9344  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2, 1, 4]          \n",
      "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
      "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      "  6                  -1  2    174720  ultralytics.nn.modules.block.A2C2f           [128, 128, 2, True, 4]        \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  6                  -1  2    174720  ultralytics.nn.modules.block.A2C2f           [128, 128, 2, True, 4]        \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  2    677120  ultralytics.nn.modules.block.A2C2f           [256, 256, 2, True, 1]        \n",
      "  9                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 10             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 11                  -1  1     86912  ultralytics.nn.modules.block.A2C2f           [384, 128, 1, False, -1]      \n",
      " 12                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 13             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 14                  -1  1     24000  ultralytics.nn.modules.block.A2C2f           [256, 64, 1, False, -1]       \n",
      " 15                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 16            [-1, 11]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      "  8                  -1  2    677120  ultralytics.nn.modules.block.A2C2f           [256, 256, 2, True, 1]        \n",
      "  9                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 10             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 11                  -1  1     86912  ultralytics.nn.modules.block.A2C2f           [384, 128, 1, False, -1]      \n",
      " 12                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 13             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 14                  -1  1     24000  ultralytics.nn.modules.block.A2C2f           [256, 64, 1, False, -1]       \n",
      " 15                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 16            [-1, 11]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 17                  -1  1     74624  ultralytics.nn.modules.block.A2C2f           [192, 128, 1, False, -1]      \n",
      " 18                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 19             [-1, 8]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 17                  -1  1     74624  ultralytics.nn.modules.block.A2C2f           [192, 128, 1, False, -1]      \n",
      " 18                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 19             [-1, 8]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 20                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n",
      " 21        [14, 17, 20]  1    431452  ultralytics.nn.modules.head.Detect           [4, [64, 128, 256]]           \n",
      " 20                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n",
      " 21        [14, 17, 20]  1    431452  ultralytics.nn.modules.head.Detect           [4, [64, 128, 256]]           \n",
      "YOLOv12n summary: 497 layers, 2,520,444 parameters, 2,520,428 gradients, 6.0 GFLOPs\n",
      "\n",
      "YOLOv12n summary: 497 layers, 2,520,444 parameters, 2,520,428 gradients, 6.0 GFLOPs\n",
      "\n",
      "Transferred 688/739 items from pretrained weights\n",
      "Freezing layer 'model.21.dfl.conv.weight'\n",
      "Transferred 688/739 items from pretrained weights\n",
      "Freezing layer 'model.21.dfl.conv.weight'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/theatulgupta/Desktop/Deep Learning Project/dental-xray-cavity-detection/data/processed/train/labels.cache... 58 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 58/58 [00:00<?, ?it/s]\n",
      "/Users/theatulgupta/Desktop/Deep Learning Project/dental-xray-cavity-detection/.venv/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/theatulgupta/Desktop/Deep Learning Project/dental-xray-cavity-detection/data/processed/train/labels.cache... 58 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 58/58 [00:00<?, ?it/s]\n",
      "/Users/theatulgupta/Desktop/Deep Learning Project/dental-xray-cavity-detection/.venv/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/theatulgupta/Desktop/Deep Learning Project/dental-xray-cavity-detection/data/processed/val/labels.cache... 17 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.00125, momentum=0.9) with parameter groups 121 weight(decay=0.0), 128 weight(decay=0.0005), 127 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1m/Users/theatulgupta/Desktop/Deep Learning Project/dental-xray-cavity-detection/yolov12/runs/detect/yolov12n_dental2\u001b[0m\n",
      "Starting training for 1 epochs...\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.00125, momentum=0.9) with parameter groups 121 weight(decay=0.0), 128 weight(decay=0.0005), 127 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1m/Users/theatulgupta/Desktop/Deep Learning Project/dental-xray-cavity-detection/yolov12/runs/detect/yolov12n_dental2\u001b[0m\n",
      "Starting training for 1 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "        1/1         0G      1.437       4.14      1.255        141        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:28<00:00,  3.57s/it]\n",
      "        1/1         0G      1.437       4.14      1.255        141        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:28<00:00,  3.57s/it]/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:03<00:00,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17        499   0.000354    0.00343   0.000179   5.42e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1 epochs completed in 0.009 hours.\n",
      "Optimizer stripped from /Users/theatulgupta/Desktop/Deep Learning Project/dental-xray-cavity-detection/yolov12/runs/detect/yolov12n_dental2/weights/last.pt, 5.4MB\n",
      "Optimizer stripped from /Users/theatulgupta/Desktop/Deep Learning Project/dental-xray-cavity-detection/yolov12/runs/detect/yolov12n_dental2/weights/last.pt, 5.4MB\n",
      "Optimizer stripped from /Users/theatulgupta/Desktop/Deep Learning Project/dental-xray-cavity-detection/yolov12/runs/detect/yolov12n_dental2/weights/best.pt, 5.4MB\n",
      "\n",
      "Validating /Users/theatulgupta/Desktop/Deep Learning Project/dental-xray-cavity-detection/yolov12/runs/detect/yolov12n_dental2/weights/best.pt...\n",
      "Ultralytics 8.3.63 ðŸš€ Python-3.13.5 torch-2.9.0 CPU (Apple M1)\n",
      "Optimizer stripped from /Users/theatulgupta/Desktop/Deep Learning Project/dental-xray-cavity-detection/yolov12/runs/detect/yolov12n_dental2/weights/best.pt, 5.4MB\n",
      "\n",
      "Validating /Users/theatulgupta/Desktop/Deep Learning Project/dental-xray-cavity-detection/yolov12/runs/detect/yolov12n_dental2/weights/best.pt...\n",
      "Ultralytics 8.3.63 ðŸš€ Python-3.13.5 torch-2.9.0 CPU (Apple M1)\n",
      "YOLOv12n summary (fused): 376 layers, 2,509,124 parameters, 0 gradients, 5.8 GFLOPs\n",
      "YOLOv12n summary (fused): 376 layers, 2,509,124 parameters, 0 gradients, 5.8 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:02<00:00,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17        499   0.000355    0.00343    0.00018   5.43e-05\n",
      "        cavity_class_0         17        167   0.000714    0.00599   0.000364   0.000182\n",
      "        cavity_class_1         17        129   0.000705    0.00775   0.000355   3.55e-05\n",
      "        cavity_class_2         17         65          0          0          0          0\n",
      "        cavity_class_3         17        138          0          0          0          0\n",
      "Speed: 0.5ms preprocess, 133.4ms inference, 0.0ms loss, 0.9ms postprocess per image\n",
      "        cavity_class_0         17        167   0.000714    0.00599   0.000364   0.000182\n",
      "        cavity_class_1         17        129   0.000705    0.00775   0.000355   3.55e-05\n",
      "        cavity_class_2         17         65          0          0          0          0\n",
      "        cavity_class_3         17        138          0          0          0          0\n",
      "Speed: 0.5ms preprocess, 133.4ms inference, 0.0ms loss, 0.9ms postprocess per image\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ“ Training complete: 36.35s\n",
      "âœ“ Best weights: /Users/theatulgupta/Desktop/Deep Learning Project/dental-xray-cavity-detection/yolov12/runs/detect/yolov12n_dental2/weights/best.pt\n"
     ]
    }
   ],
   "source": [
    "model_v12 = YOLO('yolov12n.pt')\n",
    "\n",
    "# YOLOv12 has compatibility issues with MPS, use CPU instead\n",
    "device_v12 = 'cpu' if device == 'mps' else device\n",
    "if device == 'mps':\n",
    "    print(\"âš  YOLOv12 not compatible with MPS, using CPU instead\")\n",
    "\n",
    "print(f\"Training YOLOv12n on {device_v12}...\")\n",
    "start_time_v12 = time.time()\n",
    "results_v12 = model_v12.train(\n",
    "    data=data_yaml_path,\n",
    "    epochs=1,  # Change to 50 for production\n",
    "    imgsz=640,\n",
    "    batch=8,\n",
    "    name='yolov12n_dental',\n",
    "    device=device_v12,\n",
    "    verbose=True,  # Shows progress bar with epochs\n",
    "    plots=False,   # Disable plot generation\n",
    "    save=True\n",
    ")\n",
    "train_time_v12 = time.time() - start_time_v12\n",
    "\n",
    "path_v12_best_weights = results_v12.save_dir / 'weights' / 'best.pt'\n",
    "print(f\"\\nâœ“ Training complete: {train_time_v12:.2f}s\")\n",
    "print(f\"âœ“ Best weights: {path_v12_best_weights}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80306d7",
   "metadata": {},
   "source": [
    "## Profile Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "166fdec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Profiling model...\n",
      "âœ“ Parameters: 2.52M | FLOPs: 2.99G\n",
      "âœ“ Parameters: 2.52M | FLOPs: 2.99G\n"
     ]
    }
   ],
   "source": [
    "print(\"Profiling model...\")\n",
    "model_v12_trained = YOLO(path_v12_best_weights)\n",
    "\n",
    "# Move to CPU for THOP compatibility\n",
    "model_cpu = model_v12_trained.model.cpu()\n",
    "dummy_input = torch.randn(1, 3, 640, 640)\n",
    "\n",
    "flops_v12, params_v12 = profile(model_cpu, inputs=(dummy_input,), verbose=False)\n",
    "print(f\"âœ“ Parameters: {params_v12/1e6:.2f}M | FLOPs: {flops_v12/1e9:.2f}G\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454ca8f6",
   "metadata": {},
   "source": [
    "## Measure Inference Time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b87989e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Measuring inference time...\n",
      "âœ“ Avg inference: 130.52ms/image (19 test images)\n",
      "âœ“ Avg inference: 130.52ms/image (19 test images)\n"
     ]
    }
   ],
   "source": [
    "print(\"Measuring inference time...\")\n",
    "# Reload model on correct device for inference\n",
    "model_v12_trained = YOLO(path_v12_best_weights)\n",
    "\n",
    "test_images = list(test_images_path.glob('*.jpg')) + list(test_images_path.glob('*.png'))\n",
    "\n",
    "def get_avg_inference_time(model, image_list):\n",
    "    if len(image_list) == 0:\n",
    "        return 0\n",
    "    _ = model(image_list[0], verbose=False)  # Warm-up\n",
    "    total_time = 0\n",
    "    for img in image_list:\n",
    "        start = time.perf_counter()\n",
    "        _ = model(img, verbose=False)\n",
    "        total_time += time.perf_counter() - start\n",
    "    return (total_time / len(image_list)) * 1000\n",
    "\n",
    "avg_inf_time_v12 = get_avg_inference_time(model_v12_trained, test_images[:10])\n",
    "print(f\"âœ“ Avg inference: {avg_inf_time_v12:.2f}ms/image ({len(test_images)} test images)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a22f2117",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on test set...\n",
      "Ultralytics 8.3.63 ðŸš€ Python-3.13.5 torch-2.9.0 CPU (Apple M1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/theatulgupta/Desktop/Deep Learning Project/dental-xray-cavity-detection/data/processed/test/labels.cache... 19 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<?, ?it/s]\n",
      "/Users/theatulgupta/Desktop/Deep Learning Project/dental-xray-cavity-detection/.venv/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/theatulgupta/Desktop/Deep Learning Project/dental-xray-cavity-detection/data/processed/test/labels.cache... 19 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<?, ?it/s]\n",
      "/Users/theatulgupta/Desktop/Deep Learning Project/dental-xray-cavity-detection/.venv/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:03<00:00,  1.67s/it]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         19        551   0.000388    0.00481   0.000199   3.95e-05\n",
      "Speed: 1.0ms preprocess, 155.0ms inference, 0.0ms loss, 0.8ms postprocess per image\n",
      "Results saved to \u001b[1m/Users/theatulgupta/Desktop/Deep Learning Project/dental-xray-cavity-detection/yolov12/runs/detect/val2\u001b[0m\n",
      "âœ“ mAP@50: 0.0002 | mAP@50-95: 0.0000\n",
      "Speed: 1.0ms preprocess, 155.0ms inference, 0.0ms loss, 0.8ms postprocess per image\n",
      "Results saved to \u001b[1m/Users/theatulgupta/Desktop/Deep Learning Project/dental-xray-cavity-detection/yolov12/runs/detect/val2\u001b[0m\n",
      "âœ“ mAP@50: 0.0002 | mAP@50-95: 0.0000\n"
     ]
    }
   ],
   "source": [
    "print(\"Evaluating on test set...\")\n",
    "metrics_v12 = model_v12_trained.val(split='test', data=data_yaml_path, verbose=False)\n",
    "map50_v12 = metrics_v12.box.map50\n",
    "map50_95_v12 = metrics_v12.box.map\n",
    "\n",
    "print(f\"âœ“ mAP@50: {map50_v12:.4f} | mAP@50-95: {map50_95_v12:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b61e2150",
   "metadata": {},
   "source": [
    "## Save Results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b1ca076a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model and metrics...\n",
      "\n",
      "============================================================\n",
      "âœ“ Model saved: /Users/theatulgupta/Desktop/Deep Learning Project/dental-xray-cavity-detection/models/yolov12_best.pt\n",
      "âœ“ Metrics saved: /Users/theatulgupta/Desktop/Deep Learning Project/dental-xray-cavity-detection/models/yolov12_metrics.json\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"Saving model and metrics...\")\n",
    "shutil.copy(path_v12_best_weights, models_dir / 'yolov12_best.pt')\n",
    "\n",
    "metrics_data = {\n",
    "    'model': 'YOLOv12n',\n",
    "    'training_time': train_time_v12,\n",
    "    'params': params_v12 / 1e6,\n",
    "    'inference_time_ms': avg_inf_time_v12,\n",
    "    'map50': float(map50_v12),\n",
    "    'map50_95': float(map50_95_v12)\n",
    "}\n",
    "\n",
    "with open(models_dir / 'yolov12_metrics.json', 'w') as f:\n",
    "    json.dump(metrics_data, f, indent=2)\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"âœ“ Model saved: {models_dir}/yolov12_best.pt\")\n",
    "print(f\"âœ“ Metrics saved: {models_dir}/yolov12_metrics.json\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5b09a1",
   "metadata": {},
   "source": [
    "## Visualize Predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59f1984",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Visualizing sample predictions...\")\n",
    "sample_images = test_images[:3]\n",
    "fig, axes = plt.subplots(1, len(sample_images), figsize=(15, 5))\n",
    "if len(sample_images) == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "for idx, img_path in enumerate(sample_images):\n",
    "    results = model_v12_trained(img_path, verbose=False)\n",
    "    plotted = results[0].plot()[..., ::-1]  # BGR to RGB\n",
    "    axes[idx].imshow(plotted)\n",
    "    axes[idx].axis('off')\n",
    "    axes[idx].set_title(f\"Sample {idx+1}\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "print(\"\\nâœ… YOLOv12 training complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
