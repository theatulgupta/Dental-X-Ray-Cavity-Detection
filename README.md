# ğŸ¦· Dental X-Ray Cavity Detection

A deep learning project to detect dental cavities from X-ray images using **YOLOv8** and **YOLOv12**, with a **Gradio web demo** for deployment on **Hugging Face Spaces**.

---

## ğŸ“‹ Overview

This project compares two object detection models (**YOLOv8** and **YOLOv12**) trained on a public dental X-ray dataset. Users can upload an image via the web interface to detect and visualize cavities.

---

## ğŸ§  Features

- Train and evaluate YOLOv8 & YOLOv12 models on dental X-rays
- Dataset preprocessing and YOLO-format conversion
- Model comparison: parameters, training time, and inference speed
- Gradio web app for cavity detection
- Hugging Face Spaces deployment-ready

---

## ğŸ—‚ï¸ Project Structure

```text
dental-xray-cavity-detection/
â”‚
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .gitignore
â”œâ”€â”€ LICENSE
â”‚
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ yolo_v8.yaml
â”‚   â”œâ”€â”€ yolo_v12.yaml
â”‚   â””â”€â”€ app_config.yaml
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/
â”‚   â”œâ”€â”€ processed/
â”‚   â””â”€â”€ annotations/
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_data_exploration.ipynb
â”‚   â”œâ”€â”€ 02_preprocessing.ipynb
â”‚   â”œâ”€â”€ 03_yolov8_training.ipynb
â”‚   â”œâ”€â”€ 04_yolov12_training.ipynb
â”‚   â”œâ”€â”€ 05_inference_comparison.ipynb
â”‚   â””â”€â”€ 06_metrics_visualization.ipynb
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data_prep/
â”‚   â”‚   â”œâ”€â”€ split_dataset.py
â”‚   â”‚   â”œâ”€â”€ convert_to_yolo_format.py
â”‚   â”‚   â””â”€â”€ utils.py
â”‚   â”‚
â”‚   â”œâ”€â”€ training/
â”‚   â”‚   â”œâ”€â”€ train_yolov8.py
â”‚   â”‚   â”œâ”€â”€ train_yolov12.py
â”‚   â”‚   â””â”€â”€ model_utils.py
â”‚   â”‚
â”‚   â”œâ”€â”€ evaluation/
â”‚   â”‚   â”œâ”€â”€ compare_models.py
â”‚   â”‚   â”œâ”€â”€ inference_benchmark.py
â”‚   â”‚   â””â”€â”€ metrics_utils.py
â”‚   â”‚
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ app.py
â”‚   â”‚   â”œâ”€â”€ inference.py
â”‚   â”‚   â”œâ”€â”€ visualize.py
â”‚   â”‚   â””â”€â”€ helpers.py
â”‚   â”‚
â”‚   â””â”€â”€ deployment/
â”‚       â”œâ”€â”€ hf_spaces_setup.md
â”‚       â””â”€â”€ requirements_spaces.txt
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ yolov8_best.pt
â”‚   â”œâ”€â”€ yolov12_best.pt
â”‚   â””â”€â”€ model_summary.json
â”‚
â”œâ”€â”€ results/
â”‚   â”œâ”€â”€ training_logs/
â”‚   â”œâ”€â”€ metrics/
â”‚   â”‚   â”œâ”€â”€ yolov8_results.json
â”‚   â”‚   â””â”€â”€ yolov12_results.json
â”‚   â””â”€â”€ comparison_plot.png
â”‚
â””â”€â”€ app.py
```

---

## ğŸ§© Setup Instructions

### 1ï¸âƒ£ Clone the repository

```bash
git clone https://github.com/theatulgupta/Dental-X-Ray-Cavity-Detection.git
cd Dental-X-Ray-Cavity-Detection
```

### 2ï¸âƒ£ Create and activate virtual environment

**macOS/Linux:**

```bash
python3 -m venv venv
source venv/bin/activate
```

**Windows:**

```powershell
python -m venv venv
venv\Scripts\activate
```

### 3ï¸âƒ£ Install dependencies

```bash
pip install -r requirements.txt
```

### 4ï¸âƒ£ Download dataset

Download the dataset from [Kaggle Dental X-ray Dataset](https://www.kaggle.com/datasets/killa92/dental-x-ray-images-dataset?resource=download) and place it inside:

```text
data/raw/
```

### 5ï¸âƒ£ Run preprocessing

```bash
python src/data_prep/split_dataset.py
python src/data_prep/convert_to_yolo_format.py
```

### 6ï¸âƒ£ Train models

```bash
python src/training/train_yolov8.py
python src/training/train_yolov12.py
```

### 7ï¸âƒ£ Compare performance

```bash
python src/evaluation/compare_models.py
```

### 8ï¸âƒ£ Launch web app

```bash
python app.py
```

---

## ğŸš€ Deployment (Hugging Face Spaces)

Follow the instructions in [`src/deployment/hf_spaces_setup.md`](src/deployment/hf_spaces_setup.md) to deploy the Gradio app to Hugging Face Spaces.

---

## ğŸ“Š Results

| Model   | Parameters | Training Time | Inference Time (avg/img) | mAP |
| ------- | ---------- | ------------- | ------------------------ | --- |
| YOLOv8  | â€”          | â€”             | â€”                        | â€”   |
| YOLOv12 | â€”          | â€”             | â€”                        | â€”   |

> **Note:** Results will be populated after training and evaluation.

---

## ğŸ“œ License

Licensed under the MIT License â€” see [LICENSE](LICENSE) for details.

---

## ğŸ¤ Contributing

Pull requests are welcome! For major changes, please open an issue first to discuss what you'd like to modify.

---

## ğŸ‘¨â€ğŸ’» Author's 

**Atul Kumar Gupta**  
Engineer | AI & Full Stack Developer  
ğŸ”— [GitHub](https://github.com/theatulgupta) â€¢ [LinkedIn](https://linkedin.com/in/theatulgupta)

**Ankit Pawar**  
Engineer | AI & Full Stack Developer  
ğŸ”— [GitHub](https://github.com/ankit8453) â€¢ [LinkedIn](https://linkedin.com/in/theatulgupta)

**Gourav Chouhan**  
Engineer | AI & Full Stack Developer  
ğŸ”— [GitHub](https://github.com/theatulgupta) â€¢ [LinkedIn](https://linkedin.com/in/theatulgupta)

**Richa Verma**  
Engineer | AI & Full Stack Developer  
ğŸ”— [GitHub](https://github.com/theatulgupta) â€¢ [LinkedIn](https://linkedin.com/in/theatulgupta)

---

---

dental-xray-cavity-detection/
â”‚
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .gitignore
â”œâ”€â”€ LICENSE
â”‚
â”œâ”€â”€ config/
â”‚ â”œâ”€â”€ yolo_v8.yaml
â”‚ â”œâ”€â”€ yolo_v12.yaml
â”‚ â””â”€â”€ app_config.yaml
â”‚
â”œâ”€â”€ data/
â”‚ â”œâ”€â”€ raw/
â”‚ â”œâ”€â”€ processed/
â”‚ â””â”€â”€ annotations/
â”‚
â”œâ”€â”€ notebooks/
â”‚ â”œâ”€â”€ 01_data_exploration.ipynb
â”‚ â”œâ”€â”€ 02_preprocessing.ipynb
â”‚ â”œâ”€â”€ 03_yolov8_training.ipynb
â”‚ â”œâ”€â”€ 04_yolov12_training.ipynb
â”‚ â”œâ”€â”€ 05_inference_comparison.ipynb
â”‚ â””â”€â”€ 06_metrics_visualization.ipynb
â”‚
â”œâ”€â”€ src/
â”‚ â”œâ”€â”€ data_prep/
â”‚ â”‚ â”œâ”€â”€ split_dataset.py
â”‚ â”‚ â”œâ”€â”€ convert_to_yolo_format.py
â”‚ â”‚ â””â”€â”€ utils.py
â”‚ â”‚
â”‚ â”œâ”€â”€ training/
â”‚ â”‚ â”œâ”€â”€ train_yolov8.py
â”‚ â”‚ â”œâ”€â”€ train_yolov12.py
â”‚ â”‚ â””â”€â”€ model_utils.py
â”‚ â”‚
â”‚ â”œâ”€â”€ evaluation/
â”‚ â”‚ â”œâ”€â”€ compare_models.py
â”‚ â”‚ â”œâ”€â”€ inference_benchmark.py
â”‚ â”‚ â””â”€â”€ metrics_utils.py
â”‚ â”‚
â”‚ â”œâ”€â”€ app/
â”‚ â”‚ â”œâ”€â”€ app.py
â”‚ â”‚ â”œâ”€â”€ inference.py
â”‚ â”‚ â”œâ”€â”€ visualize.py
â”‚ â”‚ â””â”€â”€ helpers.py
â”‚ â”‚
â”‚ â””â”€â”€ deployment/
â”‚ â”œâ”€â”€ hf_spaces_setup.md
â”‚ â””â”€â”€ requirements_spaces.txt
â”‚
â”œâ”€â”€ models/
â”‚ â”œâ”€â”€ yolov8_best.pt
â”‚ â”œâ”€â”€ yolov12_best.pt
â”‚ â””â”€â”€ model_summary.json
â”‚
â”œâ”€â”€ results/
â”‚ â”œâ”€â”€ training_logs/
â”‚ â”œâ”€â”€ metrics/
â”‚ â”‚ â”œâ”€â”€ yolov8_results.json
â”‚ â”‚ â”œâ”€â”€ yolov12_results.json
â”‚ â””â”€â”€ comparison_plot.png
â”‚
â””â”€â”€ app.py

---

## ğŸ§© Setup Instructions

### 1ï¸âƒ£ Clone the repository

```bash
git clone https://github.com/<your-username>/dental-xray-cavity-detection.git
cd dental-xray-cavity-detection

2ï¸âƒ£ Create and activate virtual environment

python -m venv venv
source venv/bin/activate     # On Windows: venv\Scripts\activate

3ï¸âƒ£ Install dependencies

pip install -r requirements.txt

4ï¸âƒ£ Download dataset

Download from Kaggle Dental X-ray Datasetï¿¼
and place it inside:

data/raw/

5ï¸âƒ£ Run preprocessing

python src/data_prep/split_dataset.py
python src/data_prep/convert_to_yolo_format.py

6ï¸âƒ£ Train models

python src/training/train_yolov8.py
python src/training/train_yolov12.py

7ï¸âƒ£ Compare performance

python src/evaluation/compare_models.py

8ï¸âƒ£ Launch web app

python app.py


â¸»

ğŸš€ Deployment (Hugging Face Spaces)

Follow the instructions in:

src/deployment/hf_spaces_setup.md

to deploy the Gradio app to Hugging Face Spaces.

â¸»

ğŸ“Š Results

Model Parameters Training Time Inference Time (avg/img) mAP
YOLOv8 â€” â€” â€” â€”
YOLOv12 â€” â€” â€” â€”

(Results will be filled after training and evaluation.)

â¸»

ğŸ“œ License

Licensed under the MIT License â€” see LICENSEï¿¼ for details.

â¸»

ğŸ¤ Contributing

Pull requests are welcome!
For major changes, please open an issue first to discuss what youâ€™d like to modify.

â¸»

ğŸ‘¨â€ğŸ’» Author

Atul Kumar Gupta
Engineer | AI & Full Stack Developer
ğŸ”— GitHubï¿¼ â€¢ LinkedInï¿¼

---
```
